{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading Data\n",
    "dataset = load_dataset('lukebarousse/data_jobs')\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# Data Cleanup\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the DataFrame to a CSV file\n",
    "df.to_csv('jobs_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_csv in module pandas.core.generic:\n",
      "\n",
      "to_csv(path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, *, sep: 'str' = ',', na_rep: 'str' = '', float_format: 'str | Callable | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | list[str]' = True, index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, mode: 'str' = 'w', encoding: 'str | None' = None, compression: 'CompressionOptions' = 'infer', quoting: 'int | None' = None, quotechar: 'str' = '\"', lineterminator: 'str | None' = None, chunksize: 'int | None' = None, date_format: 'str | None' = None, doublequote: 'bool_t' = True, escapechar: 'str | None' = None, decimal: 'str' = '.', errors: 'OpenFileErrors' = 'strict', storage_options: 'StorageOptions | None' = None) -> 'str | None' method of pandas.core.frame.DataFrame instance\n",
      "    Write object to a comma-separated values (csv) file.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path_or_buf : str, path object, file-like object, or None, default None\n",
      "        String, path object (implementing os.PathLike[str]), or file-like\n",
      "        object implementing a write() function. If None, the result is\n",
      "        returned as a string. If a non-binary file object is passed, it should\n",
      "        be opened with `newline=''`, disabling universal newlines. If a binary\n",
      "        file object is passed, `mode` might need to contain a `'b'`.\n",
      "    sep : str, default ','\n",
      "        String of length 1. Field delimiter for the output file.\n",
      "    na_rep : str, default ''\n",
      "        Missing data representation.\n",
      "    float_format : str, Callable, default None\n",
      "        Format string for floating point numbers. If a Callable is given, it takes\n",
      "        precedence over other numeric formatting parameters, like decimal.\n",
      "    columns : sequence, optional\n",
      "        Columns to write.\n",
      "    header : bool or list of str, default True\n",
      "        Write out the column names. If a list of strings is given it is\n",
      "        assumed to be aliases for the column names.\n",
      "    index : bool, default True\n",
      "        Write row names (index).\n",
      "    index_label : str or sequence, or False, default None\n",
      "        Column label for index column(s) if desired. If None is given, and\n",
      "        `header` and `index` are True, then the index names are used. A\n",
      "        sequence should be given if the object uses MultiIndex. If\n",
      "        False do not print fields for index names. Use index_label=False\n",
      "        for easier importing in R.\n",
      "    mode : {'w', 'x', 'a'}, default 'w'\n",
      "        Forwarded to either `open(mode=)` or `fsspec.open(mode=)` to control\n",
      "        the file opening. Typical values include:\n",
      "    \n",
      "        - 'w', truncate the file first.\n",
      "        - 'x', exclusive creation, failing if the file already exists.\n",
      "        - 'a', append to the end of file if it exists.\n",
      "    \n",
      "    encoding : str, optional\n",
      "        A string representing the encoding to use in the output file,\n",
      "        defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      "        is a non-binary file object.\n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "        (otherwise no compression).\n",
      "        Set to ``None`` for no compression.\n",
      "        Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      "        other key-value pairs are forwarded to\n",
      "        ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      "        ``tarfile.TarFile``, respectively.\n",
      "        As an example, the following could be passed for faster compression and to create\n",
      "        a reproducible gzip archive:\n",
      "        ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      "    \n",
      "        .. versionadded:: 1.5.0\n",
      "            Added support for `.tar` files.\n",
      "    \n",
      "           May be a dict with key 'method' as compression mode\n",
      "           and other entries as additional compression options if\n",
      "           compression mode is 'zip'.\n",
      "    \n",
      "           Passing compression options as keys in dict is\n",
      "           supported for compression modes 'gzip', 'bz2', 'zstd', and 'zip'.\n",
      "    quoting : optional constant from csv module\n",
      "        Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      "        then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      "        will treat them as non-numeric.\n",
      "    quotechar : str, default '\\\"'\n",
      "        String of length 1. Character used to quote fields.\n",
      "    lineterminator : str, optional\n",
      "        The newline character or character sequence to use in the output\n",
      "        file. Defaults to `os.linesep`, which depends on the OS in which\n",
      "        this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      "    \n",
      "        .. versionchanged:: 1.5.0\n",
      "    \n",
      "            Previously was line_terminator, changed for consistency with\n",
      "            read_csv and the standard library 'csv' module.\n",
      "    \n",
      "    chunksize : int or None\n",
      "        Rows to write at a time.\n",
      "    date_format : str, default None\n",
      "        Format string for datetime objects.\n",
      "    doublequote : bool, default True\n",
      "        Control quoting of `quotechar` inside a field.\n",
      "    escapechar : str, default None\n",
      "        String of length 1. Character used to escape `sep` and `quotechar`\n",
      "        when appropriate.\n",
      "    decimal : str, default '.'\n",
      "        Character recognized as decimal separator. E.g. use ',' for\n",
      "        European data.\n",
      "    errors : str, default 'strict'\n",
      "        Specifies how encoding and decoding errors are to be handled.\n",
      "        See the errors argument for :func:`open` for a full list\n",
      "        of options.\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    None or str\n",
      "        If path_or_buf is None, returns the resulting csv format as a\n",
      "        string. Otherwise returns None.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    read_csv : Load a CSV file into a DataFrame.\n",
      "    to_excel : Write DataFrame to an Excel file.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Create 'out.csv' containing 'df' without indices\n",
      "    \n",
      "    >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      "    ...                    'mask': ['red', 'purple'],\n",
      "    ...                    'weapon': ['sai', 'bo staff']})\n",
      "    >>> df.to_csv('out.csv', index=False)  # doctest: +SKIP\n",
      "    \n",
      "    Create 'out.zip' containing 'out.csv'\n",
      "    \n",
      "    >>> df.to_csv(index=False)\n",
      "    'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      "    >>> compression_opts = dict(method='zip',\n",
      "    ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      "    >>> df.to_csv('out.zip', index=False,\n",
      "    ...           compression=compression_opts)  # doctest: +SKIP\n",
      "    \n",
      "    To write a csv file to a new folder or nested folder you will first\n",
      "    need to create it using either Pathlib or os:\n",
      "    \n",
      "    >>> from pathlib import Path  # doctest: +SKIP\n",
      "    >>> filepath = Path('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      "    >>> filepath.parent.mkdir(parents=True, exist_ok=True)  # doctest: +SKIP\n",
      "    >>> df.to_csv(filepath)  # doctest: +SKIP\n",
      "    \n",
      "    >>> import os  # doctest: +SKIP\n",
      "    >>> os.makedirs('folder/subfolder', exist_ok=True)  # doctest: +SKIP\n",
      "    >>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.to_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the DataFrame to an Excel file\n",
    "df.to_excel('jobs_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "785741"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the DataFrame to a SQL database\n",
    "\n",
    "# This requires a connection to a SQL database, we'll use sqlalchemy for this\n",
    "# !conda install -c anaconda sqlalchemy -y\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///jobs.db')\n",
    "\n",
    "df.to_sql('job_table', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "      <th>job_posted_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee México</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst (m/f/d)</td>\n",
       "      <td>Nuremberg, Germany</td>\n",
       "      <td>via Big Country Jobs</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-01-19 14:05:05</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Symanto</td>\n",
       "      <td>['python', 'r', 'sql', 'azure', 'power bi', 'e...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'excel', 'power...</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Florida, United States</td>\n",
       "      <td>2023-01-19 13:19:45</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citi</td>\n",
       "      <td>['sql', 'python', 'unix', 'excel', 'jira']</td>\n",
       "      <td>{'analyst_tools': ['excel'], 'async': ['jira']...</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Projects &amp; Solutions Data Analyst (UK Pensions)</td>\n",
       "      <td>Birmingham, UK</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2023-01-04 13:35:45</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aon</td>\n",
       "      <td>['sql', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['excel'], 'programming': ['...</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Base work from home job/internship at Mga...</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>India</td>\n",
       "      <td>2023-01-14 13:11:58</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mgadz Inc</td>\n",
       "      <td>['sas', 'sas', 'sql']</td>\n",
       "      <td>{'analyst_tools': ['sas'], 'programming': ['sa...</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56381</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Oracle Supply Chain Data Analyst</td>\n",
       "      <td>Quezon City, Metro Manila, Philippines</td>\n",
       "      <td>via Trabajo.org</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>2023-03-11 06:29:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>emerson</td>\n",
       "      <td>['oracle']</td>\n",
       "      <td>{'cloud': ['oracle']}</td>\n",
       "      <td>Mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56382</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst (m/w/d)</td>\n",
       "      <td>Jena, Jerman</td>\n",
       "      <td>melalui XING</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-03-12 06:18:18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linimed Gruppe</td>\n",
       "      <td>['sql', 'julia', 'power bi', 'dax']</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'dax'], 'progra...</td>\n",
       "      <td>Mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56383</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Amul Careers 2023 - Apply Online - Data Analys...</td>\n",
       "      <td>India</td>\n",
       "      <td>melalui Jobsleworld - Jobs In India - Job Vaca...</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>2023-03-13 06:16:28</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amul</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56384</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data &amp; Analytics Architect (w/m/x)</td>\n",
       "      <td>Erfurt, Jerman</td>\n",
       "      <td>melalui LinkedIn</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-03-12 06:18:18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NTT DATA DACH</td>\n",
       "      <td>['aws', 'azure']</td>\n",
       "      <td>{'cloud': ['aws', 'azure']}</td>\n",
       "      <td>Mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56385</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CRM Data Analyst</td>\n",
       "      <td>Bad Rodach, Jerman</td>\n",
       "      <td>melalui BeBee Deutschland</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-03-12 06:18:18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HABA FAMILYGROUP</td>\n",
       "      <td>['sas', 'sas', 'sql', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['sas', 'excel'], 'programmi...</td>\n",
       "      <td>Mar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56386 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      job_title_short                                          job_title  \\\n",
       "0        Data Analyst                                       Data Analyst   \n",
       "1        Data Analyst                               Data Analyst (m/f/d)   \n",
       "2        Data Analyst                                       Data Analyst   \n",
       "3        Data Analyst    Projects & Solutions Data Analyst (UK Pensions)   \n",
       "4        Data Analyst  Data Base work from home job/internship at Mga...   \n",
       "...               ...                                                ...   \n",
       "56381    Data Analyst                   Oracle Supply Chain Data Analyst   \n",
       "56382    Data Analyst                               Data Analyst (m/w/d)   \n",
       "56383    Data Analyst  Amul Careers 2023 - Apply Online - Data Analys...   \n",
       "56384    Data Analyst                 Data & Analytics Architect (w/m/x)   \n",
       "56385    Data Analyst                                   CRM Data Analyst   \n",
       "\n",
       "                                 job_location  \\\n",
       "0                Guadalajara, Jalisco, Mexico   \n",
       "1                          Nuremberg, Germany   \n",
       "2                                   Tampa, FL   \n",
       "3                              Birmingham, UK   \n",
       "4                                    Anywhere   \n",
       "...                                       ...   \n",
       "56381  Quezon City, Metro Manila, Philippines   \n",
       "56382                            Jena, Jerman   \n",
       "56383                                   India   \n",
       "56384                          Erfurt, Jerman   \n",
       "56385                      Bad Rodach, Jerman   \n",
       "\n",
       "                                                 job_via job_schedule_type  \\\n",
       "0                                       via BeBee México         Full-time   \n",
       "1                                   via Big Country Jobs         Full-time   \n",
       "2                                           via LinkedIn         Full-time   \n",
       "3                                           via LinkedIn         Full-time   \n",
       "4                                           via LinkedIn         Full-time   \n",
       "...                                                  ...               ...   \n",
       "56381                                    via Trabajo.org         Full-time   \n",
       "56382                                       melalui XING   Pekerjaan tetap   \n",
       "56383  melalui Jobsleworld - Jobs In India - Job Vaca...   Pekerjaan tetap   \n",
       "56384                                   melalui LinkedIn   Pekerjaan tetap   \n",
       "56385                          melalui BeBee Deutschland   Pekerjaan tetap   \n",
       "\n",
       "       job_work_from_home         search_location     job_posted_date  \\\n",
       "0                   False                  Mexico 2023-01-14 13:18:07   \n",
       "1                   False                 Germany 2023-01-19 14:05:05   \n",
       "2                   False  Florida, United States 2023-01-19 13:19:45   \n",
       "3                   False          United Kingdom 2023-01-04 13:35:45   \n",
       "4                    True                   India 2023-01-14 13:11:58   \n",
       "...                   ...                     ...                 ...   \n",
       "56381               False             Philippines 2023-03-11 06:29:07   \n",
       "56382               False                 Germany 2023-03-12 06:18:18   \n",
       "56383               False                   India 2023-03-13 06:16:28   \n",
       "56384               False                 Germany 2023-03-12 06:18:18   \n",
       "56385               False                 Germany 2023-03-12 06:18:18   \n",
       "\n",
       "       job_no_degree_mention  job_health_insurance     job_country  \\\n",
       "0                      False                 False          Mexico   \n",
       "1                      False                 False         Germany   \n",
       "2                      False                 False   United States   \n",
       "3                      False                 False  United Kingdom   \n",
       "4                      False                 False           India   \n",
       "...                      ...                   ...             ...   \n",
       "56381                  False                 False     Philippines   \n",
       "56382                  False                 False         Germany   \n",
       "56383                  False                 False           India   \n",
       "56384                  False                 False         Germany   \n",
       "56385                  False                 False         Germany   \n",
       "\n",
       "      salary_rate  salary_year_avg  salary_hour_avg  \\\n",
       "0            None              NaN              NaN   \n",
       "1            None              NaN              NaN   \n",
       "2            None              NaN              NaN   \n",
       "3            None              NaN              NaN   \n",
       "4            None              NaN              NaN   \n",
       "...           ...              ...              ...   \n",
       "56381        None              NaN              NaN   \n",
       "56382        None              NaN              NaN   \n",
       "56383        None              NaN              NaN   \n",
       "56384        None              NaN              NaN   \n",
       "56385        None              NaN              NaN   \n",
       "\n",
       "                     company_name  \\\n",
       "0      Hewlett Packard Enterprise   \n",
       "1                         Symanto   \n",
       "2                            Citi   \n",
       "3                             Aon   \n",
       "4                       Mgadz Inc   \n",
       "...                           ...   \n",
       "56381                     emerson   \n",
       "56382              linimed Gruppe   \n",
       "56383                        Amul   \n",
       "56384               NTT DATA DACH   \n",
       "56385            HABA FAMILYGROUP   \n",
       "\n",
       "                                              job_skills  \\\n",
       "0      ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "1      ['python', 'r', 'sql', 'azure', 'power bi', 'e...   \n",
       "2             ['sql', 'python', 'unix', 'excel', 'jira']   \n",
       "3                                       ['sql', 'excel']   \n",
       "4                                  ['sas', 'sas', 'sql']   \n",
       "...                                                  ...   \n",
       "56381                                         ['oracle']   \n",
       "56382                ['sql', 'julia', 'power bi', 'dax']   \n",
       "56383                                               None   \n",
       "56384                                   ['aws', 'azure']   \n",
       "56385                     ['sas', 'sas', 'sql', 'excel']   \n",
       "\n",
       "                                         job_type_skills job_posted_month  \n",
       "0      {'analyst_tools': ['power bi', 'tableau'], 'pr...              Jan  \n",
       "1      {'analyst_tools': ['power bi', 'excel', 'power...              Jan  \n",
       "2      {'analyst_tools': ['excel'], 'async': ['jira']...              Jan  \n",
       "3      {'analyst_tools': ['excel'], 'programming': ['...              Jan  \n",
       "4      {'analyst_tools': ['sas'], 'programming': ['sa...              Jan  \n",
       "...                                                  ...              ...  \n",
       "56381                              {'cloud': ['oracle']}              Mar  \n",
       "56382  {'analyst_tools': ['power bi', 'dax'], 'progra...              Mar  \n",
       "56383                                               None              Mar  \n",
       "56384                        {'cloud': ['aws', 'azure']}              Mar  \n",
       "56385  {'analyst_tools': ['sas', 'excel'], 'programmi...              Mar  \n",
       "\n",
       "[56386 rows x 18 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_DA = df[(df['job_title_short'] == 'Data Analyst')].copy()\n",
    "df_DA['job_posted_month'] = df_DA['job_posted_date'].dt.strftime('%b')\n",
    "\n",
    "months = df_DA['job_posted_month'].unique()\n",
    "df_DA_month = {}\n",
    "for month in months:\n",
    "    df_DA_month[month] = df_DA[df_DA['job_posted_month'] == month].copy()\n",
    "\n",
    "quarter_1 = [df_DA_month['Jan'], df_DA_month['Feb'], df_DA_month['Mar']]\n",
    "df_concat = pd.concat(quarter_1, ignore_index=True)\n",
    "\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.to_csv('jobs_1st_quarter.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
